# install K3s on each node

# determine if this node is the control plane
- name: Check if control plane
  ansible.builtin.set_fact:
    is_control_plane: "{{ control_plane == inventory_hostname }}"

- name: Output control plane status
  ansible.builtin.debug:
    var: is_control_plane

- name: Get k3s script
  ansible.builtin.get_url:
    url: https://get.k3s.io
    dest: /tmp/k3s.sh
    mode: "0755"

- name: Execute control plane tasks
  ansible.builtin.include_tasks: control.yml
  when: is_control_plane

- name: Configure kubectl for the execution environment
  ansible.builtin.include_tasks: kubeconfig.yml

- name: Execute worker node tasks
  ansible.builtin.include_tasks: worker.yml
  when: not is_control_plane

- name: Wait for all kube-system pods become created
  ansible.builtin.command:
    kubectl get pod -n kube-system --output jsonpath='{.items[*].metadata.name}'
  delegate_to: localhost
  run_once: true
  register: control_plane_pods_created
  until: item in control_plane_pods_created.stdout
  retries: 6
  delay: 10
  loop:
    - coredns
    - local-path-provisioner
    - metrics-server
  changed_when: false

- name: Wait for all pods become ready
  ansible.builtin.command:
    kubectl wait -n kube-system pods --all --for condition=Ready --timeout=100s
  delegate_to: localhost
  run_once: true
  register: control_plane_pods_ready
  changed_when: false

# I don't know why this is required but we repeatedly have issues with ingress
# install locking up on the ingress-nginx-nginx-admission-patch job. I have
# added logic to the ingress task to reboot all nodes if the install fails but
# this is clunky as that runs in a role for localhost. So I'm adding this here
# to reboot all nodes in parallel once kube-system pods are ready.
- name: Reboot nodes after installing k3s
  ansible.builtin.reboot:
  become: true
  when: k3s_install_occurred
